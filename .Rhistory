p <- data0[row, "polity2"]
if(is.na(p)) {
print(p)
polity[n] <- p
# print(paste("On", ___,
#             "the stock price was", ___))
} else {
data0[row, "poloty2"] <- polity[n]
# print(paste("The date:", ___,
#             "is not an important day!"))
}
}
n <- data0[row,"country"]
p <- data0[row, "polity2"]
if(is.na(p)) {
print("??")
polity[n] <- p
# print(paste("On", ___,
#             "the stock price was", ___))
} else {
data0[row, "poloty2"] <- polity[n]
# print(paste("The date:", ___,
#             "is not an important day!"))
}
# Load data
library(cidata)
library(dplyr)
library(ggplot2)
tenure <- readr::read_csv("aer_primarysample.csv")
sensitivity_analysis <- function(.data, model_A, model_Y, assoc_A, assoc_Y) {
n <- nrow(.data)
# Obtain residuals with residuals()
# Obtain residual variances with sigma()
res_A <- residuals(model_A)
res_var_A <- sigma(model_A)^2
res_Y <- residuals(model_Y)
res_var_Y <- sigma(model_Y)^2
# Compute the mean and variance of U given A and Y
mean_U_term1 <- (assoc_A/res_var_A)*res_A
mean_U_term2 <- (((res_var_A - assoc_A^2)*assoc_Y)/(res_var_A*res_var_Y))*res_Y
mean_U <- mean_U_term1 + mean_U_term2
var_U_term1 <- (res_var_A - assoc_A^2)/(res_var_A*res_var_Y)
var_U_term2 <- res_var_Y - assoc_Y^2 + ((assoc_A*assoc_Y)^2)/res_var_A
var_U <- var_U_term1*var_U_term2
# Simulate U and add it to the data
U <- rnorm(n, mean = mean_U, sd = sqrt(var_U))
.data$U <- U
print("????")
########################################################################
# The part below is the only part you need to change to implement
# the sensitivity analysis in a new context.
# Refit model to estimate the causal effect
updated_model <- lm(tenure_policy_school ~ female+gncs + phd_rank + post_doc + ug_students + grad_students + faculty + full_av_salary + assist_av_salary + revenue + female_ratio + full_ratio + top_pubs5+U, data = .data)
# The names of the coefficients and confidence interval output rows
# are called "A" for the treatment variable A.
# This will change in a new dataset.
list(c(
estimate = unname(coefficients(updated_model)["gncs"]),
ci_95_lower = confint(updated_model)["gncs",1],
ci_95_upper = confint(updated_model)["gncs",2]
))
}
# Begin the sensitivity analysis
# Fit required models for the sensitivity analysis
mod_A <- lm(gncs ~ female + phd_rank + post_doc + ug_students + grad_students + faculty + full_av_salary + assist_av_salary + revenue + female_ratio + full_ratio, data = tenure)
mod_Y <- lm(tenure_policy_school ~ female+gncs + phd_rank + post_doc + ug_students + grad_students + faculty + full_av_salary + assist_av_salary + revenue + female_ratio + full_ratio + top_pubs5, data = tenure)
# Set up degree of association between U and A and between U and Y
# The U->A associations have some constraints: we set up values
# for the U->A associations that are at most equal to the
# standard deviation of the residuals from the model for A.
U_A_assocs <- seq(from = 0.05, to = sigma(mod_A), length.out = 10)
U_Y_assocs <- seq(from = 0.5, to = 6, by = 0.5)
# Form all combinations of the U->A and U->Y sensitivity parameters
sens_data <- expand.grid(U_A = U_A_assocs, U_Y = U_Y_assocs)
# Run sensitivity analysis
sens_data <- sens_data %>%
group_by(U_A, U_Y) %>%
mutate(sens = sensitivity_analysis(tenure, mod_A, mod_Y, U_A, U_Y))
head(data0)
head(data1)
data0
data1
polity
polity=data.frame()
polity
polity=data.frame()
for (row in 1:nrow(data0)) {
n <- data0[row,"country"]
p <- data0[row, "polity2"]
if(is.na(p)) {
polity[n] <- p
# print(paste("On", ___,
#             "the stock price was", ___))
} else {
data0[row, "poloty2"] <- polity[n]
# print(paste("The date:", ___,
#             "is not an important day!"))
}
}
polity=list()
for (row in 1:nrow(data0)) {
n <- data0[row,"country"]
p <- data0[row, "polity2"]
if(is.na(p)) {
polity[n] <- p
# print(paste("On", ___,
#             "the stock price was", ___))
} else {
data0[row, "poloty2"] <- polity[n]
# print(paste("The date:", ___,
#             "is not an important day!"))
}
}
polity=list()
for (row in 1:nrow(data0)) {
n <- data0[row,"country"]
p <- data0[row, "polity2"]
if(is.na(p)) {
polity$n <- p
# print(paste("On", ___,
#             "the stock price was", ___))
} else {
data0[row, "poloty2"] <- polity$n
# print(paste("The date:", ___,
#             "is not an important day!"))
}
}
polity
polity=list()
for (row in 1:nrow(data0)) {
n <- data0[row,"country"]
p <- data0[row, "polity2"]
if(is.na(p)) {
polity$n <- p
# print(paste("On", ___,
#             "the stock price was", ___))
} else {
data0[row, "poloty2"] <- polity$n
# print(paste("The date:", ___,
#             "is not an important day!"))
}
}
polity=list()
for (row in 1:nrow(data0)) {
n <- data0[row,"country"]
p <- data0[row, "polity2"]
if(is.na(p)) {
polity[[n]] <- p
# print(paste("On", ___,
#             "the stock price was", ___))
} else {
data0[row, "poloty2"] <- polity$n
# print(paste("The date:", ___,
#             "is not an important day!"))
}
}
polity=list()
polity$h=4
polity
polity=list()
n <- data0[row,"country"]
p <- data0[row, "polity2"]
polity$n=p
polity
n
polity=list()
n <- data0[row,"country"]
p <- data0[row, "polity2"]
polity$n=p
polity
p
polity=list()
n <- data0[row,"country"]
p <- data0[row, "polity2"]
print(n,p)
polity$n=p
polity
if (!require("devtools")) install.packages("devtools")
devtools::install_github("mkuhn/dict")
# Loading
library(dplyr)
library("readxl")
library(haven)
library(dict)
polity=dict()
for (row in 1:nrow(data0)) {
n <- data0[row,"country"]
p <- data0[row, "polity2"]
if(is.na(p)) {
polity[[n]] <- p
# print(paste("On", ___,
#             "the stock price was", ___))
} else {
data0[row, "poloty2"] <- polity[[n]]
# print(paste("The date:", ___,
#             "is not an important day!"))
}
}
library(dict)
d <- dict()
d[[1]] <- 42
d[[c(2, 3)]] <- "Hello!"
d <- dict()
d[[1]] <- 42
d[["foo"]] <- "bar"
d[[1]]
d[[c(2, 3)]]
d <- dict()
d[[1]] <- 42
d[["foo"]] <- "bar"
d[[1]]
d$get("not here", "default")
d$keys()
d$values()
d$items()
# [[ ]] gives an error for unknown keys
d[["?"]]
d
d$keys()
d$get(1, "default")
d[[1]]
!is.na(NA)
polity=dict()
for (row in 1:nrow(data0)) {
n <- data0[row,"country"]
p <- data0[row, "polity2"]
if(!is.na(p)) {
polity[[n]] <- p
# print(paste("On", ___,
#             "the stock price was", ___))
} else {
data0[row, "poloty2"] <- polity[[n]]
# print(paste("The date:", ___,
#             "is not an important day!"))
}
}
polity=dict()
for (row in 1:nrow(data0)) {
n <- data0[row,"country"]
p <- data0[row, "polity2"]
print(typeof(n),typeof(p))
if(!is.na(p)) {
polity[[n]] <- p
# print(paste("On", ___,
#             "the stock price was", ___))
} else {
data0[row, "poloty2"] <- polity[[n]]
# print(paste("The date:", ___,
#             "is not an important day!"))
}
}
polity=dict()
for (row in 1:nrow(data0)) {
n <- data0[row,"country"]
p <- data0[row, "polity2"]
print(typeof(n))
print(typeof(p))
if(!is.na(p)) {
polity[[n]] <- p
# print(paste("On", ___,
#             "the stock price was", ___))
} else {
data0[row, "poloty2"] <- polity[[n]]
# print(paste("The date:", ___,
#             "is not an important day!"))
}
}
polity=dict()
for (row in 1:nrow(data0)) {
n <- data0[row,"country"]
p <- data0[row, "polity2"]
print(typeof(n[0]))
print(typeof(p[0]))
if(!is.na(p)) {
polity[[n]] <- p
# print(paste("On", ___,
#             "the stock price was", ___))
} else {
data0[row, "poloty2"] <- polity[[n]]
# print(paste("The date:", ___,
#             "is not an important day!"))
}
}
for (row in 1:nrow(data0)) {
n <- data0[row,"country"]
p <- data0[row, "polity2"]
print(typeof(n[[0]]))
print(typeof(p[[0]]))
if(!is.na(p)) {
polity[[n]] <- p
# print(paste("On", ___,
#             "the stock price was", ___))
} else {
data0[row, "poloty2"] <- polity[[n]]
# print(paste("The date:", ___,
#             "is not an important day!"))
}
}
polity=list()
n <- data0[row,"country"]
p <- data0[row, "polity2"]
typeof(n)
typeof(p)
polity=list()
n <- data0[row,"country"]
p <- data0[row, "polity2"]
typeof(n)
typeof(p)
n
p
n <- data0[row,"country"]
p <- data0[row, "polity2"]
typeof(n[country])
n <- data0[row,"country"]
p <- data0[row, "polity2"]
typeof(n["country"])
typeof(p["polity2"])
n[country]
polity=list()
n <- data0[row,"country"]
p <- data0[row, "polity2"]
typeof(n["country"])
typeof(p["polity2"])
n["country"]
p["polity2"]
polity=list()
n <- data0[row,"country"]
p <- data0[row, "polity2"]
typeof(n[,"country"])
typeof(p[,"polity2"])
n["country"]
p["polity2"]
cbind(n["country"],p["polity2"])
polity=list()
n <- data0[row,"country"]
p <- data0[row, "polity2"]
typeof(n[,"country"])
typeof(p[,"polity2"])
n["country"]
p["polity2"]
m=cbind(n["country"],p["polity2"])
rbind(m,c(n["country"],p["polity2"]))
uninstall.packages(dict)
data0
data1
data0
data1
data0
data1
data0
data = read.csv("/Users/lingma/PycharmProjects/Test/processed.csv")
data = read.csv("/Users/lingma/PycharmProjects/Test/processed.csv")
data
data = read.csv("/Users/lingma/PycharmProjects/Test/processed.csv")
data
data = read.csv("/Users/lingma/PycharmProjects/Test/processed.csv")
data
data = read.csv("/Users/lingma/PycharmProjects/Test/processed.csv")
data
data = read.csv("/Users/lingma/PycharmProjects/Test/processed.csv")
data
data = read.csv("/Users/lingma/PycharmProjects/Test/processed.csv")
data
data = read.csv("/Users/lingma/PycharmProjects/Test/processed.csv")
data
data = read.csv("processed.csv")
data
data = read.csv("processed.csv")
data
install.packages("naniar")
vis_miss(data)
library(naniar)
vis_miss(data)
vis_miss(data)
vis_miss(data,cluster = TRUE)
# Loading
library(dplyr)
library(naniar)
data = read.csv("processed.csv")
setwd("~/Documents/2020fall/stat451/foreign_aid")
# Loading
library(dplyr)
library(naniar)
data = read.csv("processed.csv")
data
vis_miss(data)
vis_miss(data,cluster = TRUE)
usdata = data %>%
select(-Chinese_ODA,-Chinese_aid_total)
usDropData = na.omit(usdata)
vis_miss(usDropData)
usdata = data %>%
select(-Chinese_ODA,-Chinese_aid_total) %>%
na.omit(data)
usdata
usdata = data %>%
select(-Chinese_ODA,-Chinese_aid_total,-X) %>%
na.omit(data)
usdata
install.packages("merTools")
aid
aid = read.csv("processed.csv")
aid
aid = read.csv("processed.csv")
aid
vis_miss(aid)
vis_miss(aid,cluster = TRUE)
testImplications <- function( covariance.matrix, sample.size ){
library(ggm)
tst <- function(i){ pcor.test( pcor(i,covariance.matrix), length(i)-2, sample.size )$pvalue }
tos <- function(i){ paste(i,collapse=" ") }
implications <- list(c("polity2","population_growth_rate"),
c("rest_world_aid","A:US_ODA","polity2","recipient_trade_world"),
c("rest_world_aid","population_growth_rate","recipient_trade_world","polity2"),
c("A:US_ODA","population_growth_rate","recipient_trade_world","polity2"))
data.frame( implication=unlist(lapply(implications,tos)),
pvalue=unlist( lapply( implications, tst ) ) )
}
testImplications
dag {
library(dagitty)
dag <- dagitty("
dag {
bb=\"0,0,1,1\"
A [exposure,pos=\"0.300,0.500\"]
W [pos=\"0.550,0.280\"]
Y [outcome,pos=\"0.600,0.500\"]
Z [pos=\"0.350,0.280\"]
A -> Y
W -> A
W -> Y
Z -> A
Z -> Y
}
")
plot(dag)
dag <- dagitty("
dag {
bb=\"0,0,1,1\"
\"A:US_ODA\" [exposure,pos=\"0.272,0.239\"]
\"Y:Recipient_GDP_growth_rate\" [outcome,pos=\"0.672,0.254\"]
national_demand [latent,pos=\"0.540,0.050\"]
oda_gni [pos=\"0.446,0.310\"]
polity2 [pos=\"0.357,0.039\"]
population_growth_rate [pos=\"0.651,0.028\"]
recipient_trade_world [pos=\"0.412,0.504\"]
rest_world_aid [pos=\"0.397,0.159\"]
\"A:US_ODA\" -> \"Y:Recipient_GDP_growth_rate\"
\"A:US_ODA\" -> oda_gni
national_demand -> \"Y:Recipient_GDP_growth_rate\"
national_demand -> oda_gni
national_demand -> recipient_trade_world
oda_gni -> \"Y:Recipient_GDP_growth_rate\"
polity2 -> \"A:US_ODA\"
polity2 -> \"Y:Recipient_GDP_growth_rate\"
polity2 -> national_demand
polity2 -> rest_world_aid
population_growth_rate -> \"Y:Recipient_GDP_growth_rate\"
population_growth_rate -> national_demand
recipient_trade_world -> \"A:US_ODA\"
recipient_trade_world -> \"Y:Recipient_GDP_growth_rate\"
recipient_trade_world -> rest_world_aid
rest_world_aid -> \"Y:Recipient_GDP_growth_rate\"
rest_world_aid -> oda_gni
}
")
dag <- dagitty("
dag {
bb=\"0,0,1,1\"
\"A:US_ODA\" [exposure,pos=\"0.272,0.239\"]
\"Y:Recipient_GDP_growth_rate\" [outcome,pos=\"0.672,0.254\"]
national_demand [latent,pos=\"0.540,0.050\"]
oda_gni [pos=\"0.446,0.310\"]
polity2 [pos=\"0.357,0.039\"]
population_growth_rate [pos=\"0.651,0.028\"]
recipient_trade_world [pos=\"0.412,0.504\"]
rest_world_aid [pos=\"0.397,0.159\"]
\"A:US_ODA\" -> \"Y:Recipient_GDP_growth_rate\"
\"A:US_ODA\" -> oda_gni
national_demand -> \"Y:Recipient_GDP_growth_rate\"
national_demand -> oda_gni
national_demand -> recipient_trade_world
oda_gni -> \"Y:Recipient_GDP_growth_rate\"
polity2 -> \"A:US_ODA\"
polity2 -> \"Y:Recipient_GDP_growth_rate\"
polity2 -> national_demand
polity2 -> rest_world_aid
population_growth_rate -> \"Y:Recipient_GDP_growth_rate\"
population_growth_rate -> national_demand
recipient_trade_world -> \"A:US_ODA\"
recipient_trade_world -> \"Y:Recipient_GDP_growth_rate\"
recipient_trade_world -> rest_world_aid
rest_world_aid -> \"Y:Recipient_GDP_growth_rate\"
rest_world_aid -> oda_gni
}
")
plot(dag)
# Loading
library(dplyr)
library(naniar)
library(lme4)
library(ggplot2)
library(merTools) #we use this package because we need to use the "predictInterval" function
aid = read.csv("processed.csv")
head(aid)
aid = aid %>%
select(-Chinese_ODA,-Chinese_aid_total) %>%
na.omit(aid)
vis_miss(aid)
vis_miss(aid,cluster = TRUE)
aid = aid %>%
na.omit(aid)
